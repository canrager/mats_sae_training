{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import joseph\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "\n",
    "reload(joseph.analysis)\n",
    "reload(joseph.visualisation)\n",
    "reload(joseph.utils)\n",
    "reload(joseph.data)\n",
    "\n",
    "from joseph.analysis import *\n",
    "from joseph.visualisation import *\n",
    "from joseph.utils import *\n",
    "from joseph.data import *\n",
    "\n",
    "# turn torch grad tracking off\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    fold_ln=True,\n",
    ")\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# path = \"../artifacts/sparse_autoencoder_gpt2-small_blocks.8.hook_resid_pre_24576:v9/final_sparse_autoencoder_gpt2-small_blocks.8.hook_resid_pre_24576.pt\"\n",
    "path = \"../artifacts/sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_24576:v19/final_sparse_autoencoder_gpt2-small_blocks.10.hook_resid_pre_24576.pt\"\n",
    "sparse_autoencoder = SparseAutoencoder.load_from_pretrained(path)\n",
    "\n",
    "print(sparse_autoencoder.cfg)\n",
    "\n",
    "\n",
    "# sanity check\n",
    "text = \"Many important transition points in the history of science have been moments when science 'zoomed in.' At these points, we develop a visualization or tool that allows us to see the world in a new level of detail, and a new field of science develops to study the world through this lens.\"\n",
    "display(model(text, return_type=\"loss\"))\n",
    "\n",
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "model, sparse_autoencoder, activation_store = LMSparseAutoencoderSessionloader.load_session_from_pretrained(\n",
    "    path\n",
    ")\n",
    "\n",
    "sparse_autoencoder.cfg.use_ghost_grads = False\n",
    "\n",
    "\n",
    "import webbrowser\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "path_to_html = \"../../feature_dashboards/gpt2-small_blocks.10.hook_resid_pre_24576\"\n",
    "def render_feature_dashboard(feature_id):\n",
    "    \n",
    "    path = f\"{path_to_html}/data_{feature_id:04}.html\"\n",
    "    \n",
    "    print(f\"Feature {feature_id}\")\n",
    "    if os.path.exists(path):\n",
    "        # with open(path, \"r\") as f:\n",
    "        #     html = f.read()\n",
    "        #     display(HTML(html))\n",
    "        webbrowser.open_new_tab(\"file://\" + os.path.abspath(path))\n",
    "    else:\n",
    "        print(\"No HTML file found\")\n",
    "    \n",
    "    return\n",
    "\n",
    "# for feature in [100,300,400]:\n",
    "#     render_feature_dashboard(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import joseph\n",
    "reload(joseph.analysis)\n",
    "from joseph.analysis import *\n",
    "\n",
    "title = \"Brackets\"\n",
    "prompt = \"The quick brown fox jumps over the lazy dog (and then the dog jumps over the fox). Then the fox jumps over the dog again (and then the dog jumps over the fox).\"\n",
    "POS_INTEREST = 18\n",
    "\n",
    "# title = \"Maths\"\n",
    "# prompt = \"120 + (30 * 2) - 10 = (30 * (53 - 20)) + 10\"\n",
    "# POS_INTEREST = 4\n",
    "\n",
    "token_df, original_cache, cache_reconstructed_query, feature_acts = eval_prompt([prompt], model, sparse_autoencoder, head_idx_override=7)\n",
    "filter_cols = [\"str_tokens\", \"unique_token\", \"context\", \"batch\", \"pos\", \"label\", \"loss\", \"loss_diff\", \"mse_loss\", \"num_active_features\", \"explained_variance\", \"kl_divergence\",\n",
    "            \"top_k_features\"]\n",
    "display(token_df[filter_cols].style.background_gradient(\n",
    "    subset=[\"loss_diff\", \"mse_loss\",\"explained_variance\", \"num_active_features\", \"kl_divergence\"],\n",
    "    cmap=\"coolwarm\"))\n",
    "\n",
    "\n",
    "\n",
    "UNIQUE_TOKEN_INTEREST = token_df[\"unique_token\"][POS_INTEREST]\n",
    "feature_acts_of_interest = feature_acts[POS_INTEREST]\n",
    "# plot_line_with_top_10_labels(feature_acts_of_interest, \"\", 25)\n",
    "# vals, inds = torch.topk(feature_acts_of_interest,39)\n",
    "\n",
    "top_k_feature_inds = (feature_acts[1:] > 0).sum(dim=0).nonzero().squeeze()\n",
    "\n",
    "features_acts_by_token_df = pd.DataFrame(\n",
    "    feature_acts[:,top_k_feature_inds[:]].detach().cpu().T,\n",
    "    index = [f\"feature_{i}\" for i in top_k_feature_inds.flatten().tolist()],\n",
    "    columns = token_df[\"unique_token\"])\n",
    "\n",
    "# features_acts_by_token_df.sort_values(by=\",/12\", ascending=False).head(10).style.background_gradient(\n",
    "#     cmap=\"coolwarm\", axis=0)\n",
    "\n",
    "# px.imshow(features_acts_by_token_df.sort_values(by=\",/12\", ascending=False).head(10).T.corr(), color_continuous_midpoint=0, color_continuous_scale=\"RdBu\")\n",
    "# n_feature_dashboards = 10\n",
    "tmp = features_acts_by_token_df.sort_values(UNIQUE_TOKEN_INTEREST, ascending=False).T\n",
    "# dashboard_features = features_acts_by_token_df.sort_values(UNIQUE_TOKEN_INTEREST, ascending=False).index[:n_feature_dashboards].to_series().apply(lambda x: x.split(\"_\")[1]).tolist()\n",
    "# for feature in dashboard_features:\n",
    "#     render_feature_dashboard(feature)\n",
    "\n",
    "px.line(tmp + 1e-5,\n",
    "        # log_y=True,\n",
    "        title=f\"{title}: Features Activation by Token in Prompt\", \n",
    "        color_discrete_sequence=px.colors.qualitative.Plotly,\n",
    "        height=500).show()\n",
    "\n",
    "tmp = features_acts_by_token_df.head(100).T\n",
    "px.imshow(tmp, \n",
    "            title=f\"{title}: Top k features by activation\", \n",
    "            color_continuous_midpoint=0, \n",
    "            color_continuous_scale=\"RdBu\", \n",
    "            height=800).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render_feature_dashboard(17159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interp Experiment\n",
    "\n",
    "Let's contruct a bunch of cases where we have brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bracket_prompt():\n",
    "    \n",
    "    left_bracket_token = torch.tensor(model.to_single_token(\"(\")).unsqueeze(0).repeat(1,256)\n",
    "    right_bracket_token = torch.tensor(model.to_single_token(\")\")).unsqueeze(0).repeat(1,256)\n",
    "    random_tokens = torch.randint(0, 50257, (10,256))\n",
    "    \n",
    "    # add the brackets after the first two tokens and before the last two tokensx\n",
    "    prompt = torch.concat([random_tokens[:2], left_bracket_token, random_tokens[2:-2:], right_bracket_token, random_tokens[-2:]], dim=0).T\n",
    "    return prompt\n",
    "\n",
    "tokens = generate_bracket_prompt()\n",
    "(original_logits, original_loss), original_cache = model.run_with_cache(tokens, return_type=\"both\", loss_per_token=True)\n",
    "\n",
    "original_act = original_cache[sparse_autoencoder.cfg.hook_point]\n",
    "sae_out, feature_acts, _, mse_loss, _, _ = sparse_autoencoder(original_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_string(tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Feature Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_of_interest= 17159\n",
    "px.line(feature_acts[:,:,feature_of_interest].mean(0).T.detach().cpu()).show()\n",
    "px.line(feature_acts[:,:,feature_of_interest].T.detach().cpu()).show()\n",
    "w_dec_bracket_10 = sparse_autoencoder.W_dec[feature_of_interest].detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFA\n",
    "decomp, labels = original_cache.decompose_resid(return_labels=True, layer = 10)\n",
    "proj = decomp.detach().cpu() @ w_dec_bracket_10\n",
    "proj_df = pd.DataFrame(proj.mean(1).T, columns=labels, index = range(proj.shape[2]))\n",
    "# px.imshow(proj_df.T, title=\"Projection of Residuals onto Bracket Feature\", color_continuous_midpoint=0, color_continuous_scale=\"RdBu\")\n",
    "px.line(proj_df.T, title=\"Projection of Residuals onto Bracket Feature\", color_discrete_sequence=px.colors.qualitative.Plotly).show()\n",
    "\n",
    "decomp, labels = original_cache.accumulated_resid(return_labels=True, layer = 10, incl_mid=True)\n",
    "\n",
    "proj = decomp.detach().cpu() @ w_dec_bracket_10\n",
    "proj_df = pd.DataFrame(proj.mean(1).T, columns=labels, index = range(proj.shape[2]))\n",
    "# px.imshow(proj_df.T, title=\"Projection of Residuals onto Bracket Feature\", color_continuous_midpoint=0, color_continuous_scale=\"RdBu\")\n",
    "px.line(proj_df.T, title=\"Projection of Residuals onto Bracket Feature (Accumulated)\", color_discrete_sequence=px.colors.qualitative.Plotly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFA\n",
    "decomp, labels = original_cache.get_full_resid_decomposition(return_labels=True, layer = 10, expand_neurons=False)\n",
    "proj = decomp.detach().cpu() @ w_dec_bracket\n",
    "proj_df = pd.DataFrame(proj.mean(1).T, columns=labels, index = range(proj.shape[2]))\n",
    "# px.imshow(proj_df.T, title=\"Projection of Residuals onto Bracket Feature\", color_continuous_midpoint=0, color_continuous_scale=\"RdBu\")\n",
    "px.line(proj_df.iloc[:,:12].T, title=\"Projection of Residuals onto Bracket Feature\", color_discrete_sequence=px.colors.qualitative.Plotly).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.imshow(\n",
    "    original_cache['blocks.0.attn.hook_pattern'].mean(0).detach().cpu(),\n",
    "    facet_col=0,\n",
    "    facet_col_wrap=4,\n",
    "    title=\"Attention Patterns\",\n",
    "    color_continuous_scale=\"RdBu\",\n",
    "    color_continuous_midpoint=0,\n",
    "    height=800,\n",
    "    width=800,\n",
    "    # show all tics \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer 1 DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1_sae_path = \"../GPT2-small-SAEs/final_sparse_autoencoder_gpt2-small_blocks.1.hook_resid_pre_24576.pt\"\n",
    "sparse_autoencoder_layer_1 = SparseAutoencoder.load_from_pretrained(layer_1_sae_path)\n",
    "sparse_autoencoder_layer_1.cfg.use_ghost_grads = False\n",
    "original_act = original_cache[sparse_autoencoder_layer_1.cfg.hook_point]\n",
    "sae_out, feature_acts_layer_1, _, mse_loss, _, _ = sparse_autoencoder_layer_1(original_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_acts_layer_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_of_interest= 11114\n",
    "px.line(feature_acts_layer_1[:,:,feature_of_interest].mean(0).T.detach().cpu()).show()\n",
    "px.line(feature_acts_layer_1[:,:,feature_of_interest].T.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do DFA on this feature\n",
    "w_dec_bracket_layer_1 = sparse_autoencoder_layer_1.W_dec[feature_of_interest].detach().cpu()\n",
    "\n",
    "# DFA\n",
    "decomp, labels = original_cache.get_full_resid_decomposition(return_labels=True, layer = 1, expand_neurons=False)\n",
    "proj = decomp.detach().cpu() @ w_dec_bracket_layer_1\n",
    "proj_df = pd.DataFrame(proj.mean(1).T, columns=labels, index = range(proj.shape[2]))\n",
    "px.line(proj_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patching Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_bracket_prompt_clean():\n",
    "    \n",
    "    left_bracket_token = torch.tensor(model.to_single_token(\"(\")).unsqueeze(0).repeat(1,256)\n",
    "    right_bracket_token = torch.tensor(model.to_single_token(\")\")).unsqueeze(0).repeat(1,256)\n",
    "    random_tokens = torch.randint(0, 50257, (10,256))\n",
    "    \n",
    "    # add the brackets after the first two tokens and before the last two tokens\n",
    "    prompt = torch.concat([random_tokens[:2], left_bracket_token, random_tokens[2:-2:], right_bracket_token, random_tokens[-2:]], dim=0).T\n",
    "    return prompt\n",
    "\n",
    "def generate_bracket_prompt_corrupt():\n",
    "    \n",
    "    left_bracket_token = torch.tensor(model.to_single_token(\"(\")).unsqueeze(0).repeat(1,256)\n",
    "    random_tokens = torch.randint(0, 50257, (11,256))\n",
    "    \n",
    "    # add the brackets after the first two tokens and before the last two tokens\n",
    "    prompt = torch.concat([random_tokens[:2], left_bracket_token, random_tokens[2:]], dim=0).T\n",
    "    return prompt\n",
    "\n",
    "\n",
    "clean_tokens = generate_bracket_prompt_clean()\n",
    "corrupted_tokens = generate_bracket_prompt_corrupt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens, return_type=\"both\")\n",
    "clean_act = original_cache[sparse_autoencoder.cfg.hook_point]\n",
    "clean_sae_out, clean_feature_acts, _, mse_loss, _, _ = sparse_autoencoder(clean_act)\n",
    "\n",
    "_, corrupt_cache = model.run_with_cache(corrupted_tokens, return_type=\"both\")\n",
    "corrupt_act = corrupt_cache[sparse_autoencoder.cfg.hook_point]\n",
    "corrupt_sae_out, corrupt_feature_acts, _, mse_loss, _, _ = sparse_autoencoder(corrupt_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_of_interest= 17159\n",
    "px.line(\n",
    "    y=[clean_feature_acts[:,:,feature_of_interest].mean(0).T.detach().cpu(), \n",
    "     corrupt_feature_acts[:,:,feature_of_interest].mean(0).T.detach().cpu()]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I think that L0H7 seems critical, let's see if we patch the output for L0H7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "head_hook_result_name = utils.get_act_name(\"z\", 0)\n",
    "def hook_to_patch_head(\n",
    "    head_output: Float[Tensor, \"batch seq_len head_idx d_head\"], \n",
    "    hook: HookPoint, \n",
    "    head = 7,\n",
    "    pos = None,\n",
    "    from_cache = clean_cache,):\n",
    "    # print(head_output.shape)\n",
    "    if pos is None:\n",
    "        head_output[:, :, head[1], :] = from_cache[hook][:,:,head[1],:]\n",
    "    else:\n",
    "        head_output[:, pos, head[1], :] = from_cache[hook][:,pos,head[1],:]\n",
    "    return head_output\n",
    "\n",
    "with model.run_with_hooks(corrupted_tokens, fwd_hooks=[(head_hook_result_name, hook_to_patch_head)]):\n",
    "    _, patched_cache = model.run_with_cache(corrupted_tokens, return_type=\"both\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
