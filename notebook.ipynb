{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch \n",
    "from sae_training.utils import LMSparseAutoencoderSessionloader\n",
    "from huggingface_hub import hf_hub_download\n",
    "import plotly_express as px \n",
    "import pandas as pd \n",
    "\n",
    "# TORCH DON'T TRACK GRADS\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from transformer_lens import HookedTransformer\n",
    "\n",
    "# model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjbloom\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/paperspace/mats_sae_training/wandb/run-20240226_043847-v595p03d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jbloom/mats_sae_training/runs/v595p03d' target=\"_blank\">comfy-flower-13</a></strong> to <a href='https://wandb.ai/jbloom/mats_sae_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jbloom/mats_sae_training' target=\"_blank\">https://wandb.ai/jbloom/mats_sae_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jbloom/mats_sae_training/runs/v595p03d' target=\"_blank\">https://wandb.ai/jbloom/mats_sae_training/runs/v595p03d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact sparse_autoencoder_gpt2-small_blocks.3.hook_resid_pre_12288:v18, 72.10MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:1.5\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('jbloom/mats_sae_training_gpt2_ghost_grad_experiment/sparse_autoencoder_gpt2-small_blocks.3.hook_resid_pre_12288:v18', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67192acf0a345e7b78c17bb84d6727c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bac8c1da394b73a4bb73624f68425e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_sae = \"artifacts/sparse_autoencoder_gpt2-small_blocks.3.hook_resid_pre_12288:v18/270000128_sparse_autoencoder_gpt2-small_blocks.3.hook_resid_pre_12288.pt\"\n",
    "\n",
    "model, sparse_autoencoder, activation_store = LMSparseAutoencoderSessionloader.load_session_from_pretrained(path_to_sae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_training.evals import run_evals\n",
    "sparse_autoencoder.eval()\n",
    "metrics = run_evals(sparse_autoencoder, activation_store, model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metrics/l2_norm': 25.5283203125,\n",
       " 'metrics/l2_ratio': 0.9211738109588623,\n",
       " 'metrics/CE_loss_score': tensor(0.7211, device='cuda:0'),\n",
       " 'metrics/ce_loss_without_sae': tensor(3.3924, device='cuda:0'),\n",
       " 'metrics/ce_loss_with_sae': tensor(6.3396, device='cuda:0'),\n",
       " 'metrics/ce_loss_with_ablation': tensor(13.9600, device='cuda:0')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name\n",
    "from sae_training.evals import get_recons_loss\n",
    "import numpy as np\n",
    "\n",
    "hook_point = sparse_autoencoder.cfg.hook_point\n",
    "hook_point_layer = sparse_autoencoder.cfg.hook_point_layer\n",
    "hook_point_head_index = sparse_autoencoder.cfg.hook_point_head_index\n",
    "\n",
    "### Evals\n",
    "eval_tokens = activation_store.get_batch_tokens()\n",
    "\n",
    "# Get Reconstruction Score\n",
    "recons_score, ntp_loss, recons_loss, zero_abl_loss = get_recons_loss(\n",
    "    sparse_autoencoder, model, activation_store, eval_tokens\n",
    ")\n",
    "\n",
    "# get cache\n",
    "_, cache = model.run_with_cache(\n",
    "    eval_tokens,\n",
    "    prepend_bos=False,\n",
    "    names_filter=[get_act_name(\"pattern\", hook_point_layer), hook_point],\n",
    ")\n",
    "\n",
    "# get act\n",
    "if sparse_autoencoder.cfg.hook_point_head_index is not None:\n",
    "    original_act = cache[sparse_autoencoder.cfg.hook_point][\n",
    "        :, :, sparse_autoencoder.cfg.hook_point_head_index\n",
    "    ]\n",
    "else:\n",
    "    original_act = cache[sparse_autoencoder.cfg.hook_point]\n",
    "\n",
    "sae_out, feature_acts, _, _, _, _ = sparse_autoencoder(original_act)\n",
    "patterns_original = (\n",
    "    cache[get_act_name(\"pattern\", hook_point_layer)][:, hook_point_head_index]\n",
    "    .detach()\n",
    "    .cpu()\n",
    ")\n",
    "del cache\n",
    "\n",
    "if \"cuda\" in str(model.cfg.device):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if sparse_autoencoder.cfg.normalize_activations:\n",
    "    l2_norm_in = np.sqrt(sparse_autoencoder.cfg.d_in)\n",
    "else:\n",
    "    l2_norm_in = torch.norm(original_act, dim=-1)\n",
    "l2_norm_out = torch.norm(sae_out, dim=-1)\n",
    "l2_norm_ratio = l2_norm_out / l2_norm_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
